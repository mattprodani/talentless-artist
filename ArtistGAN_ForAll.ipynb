{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattprodani/talentless-artist/blob/main/ArtistGAN_ForAll.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aB1PIU6uH1O"
      },
      "source": [
        "# **PaintingGAN**\n",
        "\n",
        "Build a Machine Learning model to generate paintings based on your favorite artist.\n",
        "\n",
        "Tutorial provided by Matt Prodani - mp5908@nyu.edu\n",
        "\n",
        "Many thanks to the resources provided by NVidia, Ikarus777, and the artists that made the paintings.\n",
        "\n",
        "This Colab is published non-comercially for research under the same license as StyleGAN2 available at:\n",
        "https://nvlabs.github.io/stylegan2-ada-pytorch/license.html\n",
        "\n",
        "**First run:** Go through entire Colab adjusting as needed.\n",
        "**Continuing runs** Install dependencies, Skip accessing and preprocessing, Mount Google Drive, and continue to the section on continuing training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61yFPgswF09H"
      },
      "source": [
        "Basic Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXmfzbqRF2cv"
      },
      "outputs": [],
      "source": [
        "!pip install ninja opensimplex torch==1.7.1 torchvision==0.8.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8MZOcA2ukL8"
      },
      "source": [
        "# Accessing and processing data:\n",
        "For this step, you can upload through the files menu on the left side, or through Colab. Make note of where your files are located.\n",
        "\n",
        "This entire section only needs to be run once, at setup. The data will be saved on Google Drive for later use. You can rerun it if you want to download a new dataset for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoeDiJhTnfKM"
      },
      "source": [
        "Downloading the Kaggle dataset\n",
        "\n",
        "For this you will need a \"kaggle.json\" file which you can download by logging into kaggle and creating an authentication key on https://www.kaggle.com/me/account. \n",
        "You can then upload it through the folder on the left toolbar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT747AuKuy_I"
      },
      "outputs": [],
      "source": [
        "# Skip this cell if you are using a custom dataset\n",
        "\n",
        "# Upload kaggle.json through the files tab to the content folder.\n",
        "# - https://www.kaggle.com/me/account - Navigate to authentication, create a key and download kaggle.json\n",
        "\n",
        "\n",
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d ikarus777/best-artworks-of-all-time\n",
        "!unzip best-artworks-of-all-time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZO4zuFrAezU"
      },
      "outputs": [],
      "source": [
        "#Clean up unnecessary data\n",
        "!rm -r /content/resized\n",
        "!rm /content/artists.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tvOOgI-wyjc"
      },
      "source": [
        "The code below is specific to the structure of this dataset, to use on other datasets, follow the logic from inside the inner for loop. Then continue to the setting up StyleGAN section.\n",
        "\n",
        "Change DIMS to your preffered size, larger sizes will provide higher quality results but will take much longer. Square images are preferred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4JohwJAxdHw"
      },
      "source": [
        "Use this to see the artists available in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7YB8YbvxV5E",
        "outputId": "e3f20a37-8209-4683-d4bd-75a4de69fdca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/images/images\n",
            "Albrecht_Du╠Иrer     Frida_Kahlo\t\tPablo_Picasso\n",
            "Albrecht_DuтХа├кrer  Georges_Seurat\t\tPaul_Cezanne\n",
            "Alfred_Sisley\t     Giotto_di_Bondone\t\tPaul_Gauguin\n",
            "Amedeo_Modigliani    Gustave_Courbet\t\tPaul_Klee\n",
            "Andrei_Rublev\t     Gustav_Klimt\t\tPeter_Paul_Rubens\n",
            "Andy_Warhol\t     Henri_de_Toulouse-Lautrec\tPierre-Auguste_Renoir\n",
            "Camille_Pissarro     Henri_Matisse\t\tPieter_Bruegel\n",
            "Caravaggio\t     Henri_Rousseau\t\tPiet_Mondrian\n",
            "Claude_Monet\t     Hieronymus_Bosch\t\tRaphael\n",
            "Diego_Rivera\t     Jackson_Pollock\t\tRembrandt\n",
            "Diego_Velazquez      Jan_van_Eyck\t\tRene_Magritte\n",
            "Edgar_Degas\t     Joan_Miro\t\t\tSalvador_Dali\n",
            "Edouard_Manet\t     Kazimir_Malevich\t\tSandro_Botticelli\n",
            "Edvard_Munch\t     Leonardo_da_Vinci\t\tTitian\n",
            "El_Greco\t     Marc_Chagall\t\tVasiliy_Kandinskiy\n",
            "Eugene_Delacroix     Michelangelo\t\tVincent_van_Gogh\n",
            "Francisco_Goya\t     Mikhail_Vrubel\t\tWilliam_Turner\n"
          ]
        }
      ],
      "source": [
        "%cd /content/images/images \n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jelRdi5wwgVf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "INPUT_DIR = \"/content/images/images/\"\n",
        "OUTPUT_DIR = \"/content/resized/\"\n",
        "DIMS = (512, 512)\n",
        "\n",
        "os.mkdir(OUTPUT_DIR)\n",
        "\n",
        "# Comment the loop below to resize only a specific artist\n",
        "# Use this to resize all images\n",
        "for artist in os.listdir(INPUT_DIR):\n",
        "  os.mkdir(OUTPUT_DIR + artist)\n",
        "  for name in os.listdir(INPUT_DIR + artist):\n",
        "    raw = cv2.imread(INPUT_DIR + artist + \"/\" + name)\n",
        "    out = cv2.resize(raw, DIMS)\n",
        "    cv2.imwrite(OUTPUT_DIR + artist + \"/\" + name, out)\n",
        "\n",
        "\n",
        "# Uncomment below and comment the above paragraph to resize a specific artist, replace artist with value provided above\n",
        "# artist = \"Vincent_van_Gogh\"\n",
        "# os.mkdir(\"output/\" + artist)\n",
        "# for name in os.listdir(INPUT_DIR + artist):\n",
        "#   raw = cv2.imread(INPUT_DIR + artist + \"/\" + name)\n",
        "#   out = cv2.resize(raw, dims)\n",
        "#   cv2.imwrite(OUTPUT_DIR + artist + \"/\" + name, out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj1TU2z-xlb0"
      },
      "outputs": [],
      "source": [
        "ARTIST = \"Vincent_van_Gogh\"\n",
        "OUTPUT_DIR = \"/content/resized/\"\n",
        "!zip -r -j -q /content/dataset.zip {OUTPUT_DIR + ARTIST + \"/\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KwA4tcVDgRE"
      },
      "source": [
        "# Connecting to Google Drive\n",
        "This will allow us to save the state of our model and our dataset so we can come back to the Colab as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "05ezv-YFDywJ",
        "outputId": "1589c9ef-9929-4714-e77f-1fbf859ee689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bh-KzPoD62N"
      },
      "source": [
        "Move the dataset from temporary to Google Drive memory - this only needs to be done once. Change DATASET_LOC if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6QO1cwpEOVP"
      },
      "outputs": [],
      "source": [
        "DATASET_LOC = \"/content/dataset.zip\"\n",
        "!mkdir /content/drive/MyDrive/MyPaintingGAN\n",
        "!cp {DATASET_LOC} /content/drive/MyDrive/MyPaintingGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rddYJ8JE116"
      },
      "source": [
        "# Setting up StyleGAN2 and PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--KlKm6CFomR"
      },
      "source": [
        "Only for first run, downloads the repo for StyleGAN2 onto your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "387AadFyFTFw",
        "outputId": "9a9e11ac-28f4-4db9-a790-a37da60bab1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MyPaintingGAN\n",
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 1.12 MiB | 18.22 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/MyPaintingGAN\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the below lines to check the documentation for train.py"
      ],
      "metadata": {
        "id": "oqcBwXucLQH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEc0eznppFQu"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/MyPaintingGAN/stylegan2-ada-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y47ZD7-YpHYq"
      },
      "outputs": [],
      "source": [
        "!python train.py --help"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running StyleGAN2\n",
        "\n",
        "For the first run, adjust the dataset path if needed, and resume from if you would like to use a different resolution. The available pretrained networks to resume from can be seen by running the command above. You can also train the network without pretrained networks, but that can take very long computation times. Check the official StyleGAN repo for more information on training from scratch."
      ],
      "metadata": {
        "id": "6fBqc4gzGGyM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seEkl1CRl7no"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/MyPaintingGAN/stylegan2-ada-pytorch/\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/MyPaintingGAN/dataset.zip'\n",
        "resume_from = 'ffhq512'\n",
        "aug_strength = 0.019\n",
        "train_count = 4\n",
        "mirror_x = True\n",
        "\n",
        "gamma_value = 50.0\n",
        "augs = 'bg'\n",
        "config = '11gb-gpu'\n",
        "snapshot_count = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --gpus=1 --cfg=$config --metrics=None --outdir=./output --data=$dataset_path --snap=$snapshot_count --resume=$resume_from --augpipe=$augs --initstrength=$aug_strength --gamma=$gamma_value --mirror=$mirror_x --mirrory=False --nkimg=$train_count"
      ],
      "metadata": {
        "id": "T-3cgAFOFnBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuing the training\n",
        "\n",
        "Every 4 ticks, which you can see in the log.txt or the log from the cell above, a new snapshot of the network will be saved. This will contain your latest trained data saved as a '.pkl' or pickle file. Colab may randomly shut down the server due to its time constraints, so to train effectively you will need to continue training multiple times.\n",
        "\n",
        "After the first run, make sure to change resume from to the full path of your 'pkl' file. This will be available under /content/drive/MyDrive/MyPaintingGAN/stylegan2-ada-pytorch/output. Find the latest '.pkl' file and change resume_from to point to it every time you want to continue training. Under the output folder, you will also find sample images from the network. To generate new images use the code below."
      ],
      "metadata": {
        "id": "MbILeUsAGrOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Images from Network\n",
        "\n",
        "The code below will generate random images and store them in the output folder. To use simply set the location of the latest '.pkl' file trained above, and choose SEED_START and SEED_END. The code will generate a unique image for each seed number. \n",
        "\n",
        "Note: if you run the same network with the same seed values you will get the same pictures for each individual seed, to get different pictures, change the seed range."
      ],
      "metadata": {
        "id": "5K5p-ZvYH5cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED_START = 1\n",
        "SEED_END = 100\n",
        "NETWORK_LOCATION = \"/content/drive/MyDrive/MyPaintingGAN/stylegan2-ada-pytorch/results/yourdirectory/yournetworkfile.pkl\"\n",
        "OUTPUT = \"/content/drive/MyDrive/MyPaintingGAN/generated/\"\n",
        "\n",
        "\n",
        "!python generate.py --outdir={OUTPUT} --trunc=0.7 --seeds={SEED_START}-{SEED_END} --network={NETWORK_LOCATION}"
      ],
      "metadata": {
        "id": "952feM6cH-pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Notes\n",
        "\n",
        "This is a very basic use of StyleGAN2 with limited customization. If you would like to learn more about how it works and how to use StyleGAN efficiently, visit the Github. An important part that is ommited is testing the accuracy of the model. There are many ways in which you can validate a model, but many of them are too complicated to include here. \n",
        "\n",
        "\n",
        "\n",
        "Thanks to all the resources made available for this project:\n",
        "\n",
        "https://github.com/NVlabs/stylegan2-ada-pytorch for the network training repo.\n",
        "\n",
        "https://www.kaggle.com/ikarus777/best-artworks-of-all-time for compiling artwork to use in this project.\n",
        "\n",
        "www.artchallenge.ru for providing the artwork compiled."
      ],
      "metadata": {
        "id": "Wqh4XnZ7MBQy"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ArtistGAN_ForAll.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZYnNbGZmIVzOQhzPlhxl5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}